---
title: clm_intro
output: html_document
---

# Cumulative link models (CLMs)

RTC Methods Club, February 20, 2025

Isaac Kinley & Sabrina Valenzano

## Introduction

We know how to deal with continuous response data (linear regression) and binary data (logistic regression), but what about **ordinal data**?

Ordinal data consists of observations that fall into a series of **ordered levels**. In other words, we know how to arrange the observations in some order, but we don't know anything about the distances between levels. Importantly, even if the levels have numerical *labels*, it's still not appropriate to treat these as numerical observations on a continuous scale.

A common example of ordinal data in psychology is Likert-scale survey responses:

1.  Strongly disagree
2.  Somewhat disagree
3.  Neutral
4.  Somewhat agree
5.  Strongly agree

The wording is chosen so that successive levels seem roughly psychologically equidistant, but we still can't pretend we're working with numerical measurements on a continuous scale. In fact, we're working with *categorical* measurements on an *ordinal* scale, and cumulative link models (CLMs) are appropriate for this type of data.

## Terminology

We're using the term "CLM" today because it matches the name of the `clm` function we'll be using, but these models have many other names:

-   Ordinal regression
-   Proportional odds models
-   Ordered logit (or probit)

## CLMs vs logistic regression

To understand CLMs, it's helpful to first review logistic regression. We have some variable $Y$ that can take on values 0 or 1, and we model the probability that it takes on either value according to an intercept $\theta$ a predictor variable or set of variables $x$, and a coefficient or set of coefficients $\beta$ that estimate the relationship between $x$ and $Y$:

$$
P(Y = 1) = \sigma(\theta + \beta x)
$$

Here is how the logistic function $\sigma(x)$ looks (it's sometimes called a "sigmoid" function because it's S-shaped):

```{r}
x <- seq(-5, 5, l = 1000)
plot(plogis(x) ~ x, ylab = 'σ(x)', type = 'l')
```

It's helpful to think of CLMs as a series of logistic regressions. If our observations $Y$ fall into ordinal categories labeled 1, 2, 3, 4, and 5 (as with a Likert-type scale), our model is as follows:

$$
\begin{aligned}
P(Y \leq 1) &= \sigma(\theta_1 + \beta x) \\
P(Y \leq 2) &= \sigma(\theta_2 + \beta x) \\
P(Y \leq 3) &= \sigma(\theta_3 + \beta x) \\
P(Y \leq 4) &= \sigma(\theta_4 + \beta x) \\
P(Y \leq 5) &= 1 \\
\end{aligned}
$$

I.e., we are modelling the probability that the observation is less than or equal to 1, less than or equal to 2, etc., with a series of intercepts $\theta_1$, $\theta_2$, etc. and a single set of coefficients $\beta$. In CLM terminology, the $\theta$ variables are called **thresholds**.

## Ordinal data example

Let's generate some imaginary data. Suppose we've measured people's heights, asked whether they wear high heels, and asked how often they get recruited to grab things off the top shelf.

```{r}
set.seed(123) # So that we all have the same random data
ndata <- 1000
cont <- 1.65 + rnorm(ndata, sd = 0.07)
categ_effs <- c('A' = 0.5, 'B' = 0.6)
categ <- sample(names(categ_effs), ndata, replace = T)
latent_var <- 0.5*cont + categ_effs[categ] + rnorm(100, sd = 0.05)
data <- data.frame(
  height = cont,
  heels = factor(categ,
                     levels = c('A', 'B'),
                     labels = c('No', 'Yes')),
  top_shelf = cut(latent_var,
                  breaks = c(-Inf, quantile(latent_var,
                                            probs = c(0.1, 0.3, 0.5, 0.8)),
                             Inf),
                  labels = c('Never',
                             'Rarely',
                             'Occasionally',
                             'Frequently',
                             'Constantly'))
)
head(data)
```

Let's first visualize the association between height and top-shelf-grabbing-recruitment:

```{r}
boxplot(height ~ top_shelf, data = data)
```

It might be tempting to run `summary(lm(agreement ~ height, data = data))` and call it a day, this would be pretending our Likert-scale responses constitute a numerical measurement on a continuous scale, which they aren't.

Take a look here when we try to fit a `lm` on ordinal data - we make the false assumption of equal spacing between ordinal categories

```{r}
# Convert agreement to numeric for plotting
data$top_shelf_num <- as.numeric(data$top_shelf)

# Fit linear model
mod.lin <- lm(top_shelf_num ~ height, data = data)

# Plot regression line on raw ordinal data
plot(top_shelf_num ~ height, data = data,
     xlab = "Height", ylab = "Agreement (Numeric)",
     main = "Linear Model Fit with Ordinal Data",
     pch = 16, col = "blue")
# Add linear regression line
abline(mod.lin, col = "red")
```

As you can see, the figure illustrates that the linear model does not appropriately capture the structure of the ordinal data. The fitted regression line does not align well with the categorical nature of the outcome.

## Fitting a CLM

Instead, we'll use the `clm` function from the `ordinal` package. Although other packages, such as the `polr` function from the `MASS` package, can estimate CLMs, the `ordinal` package provides additional flexibility. Specifically, it allows for different link functions, the estimation of partial proportional odds models, and the ability to structure thresholds by specifying them as equidistant or symmetrical if appropriate.

The `clm` function uses the same syntax (Wilkinson notation) as the familiar `lm` function:

```{r}
library(ordinal)
mod <- clm(top_shelf ~ height * heels, data = data)
summary(mod)
```

This shows us that top shelf recruitment is indeed associated with height and stiletto wearing, but no interaction. Notice that there are only 4 "thresholds" or intercepts ($\theta$ in the above equations) even though there are 5 categories. This is because the probability of the observation being less than or equal to the highest category is always 1 (so the corresponding $\theta$ is always implicitly infinity).

## The proportional odds assumption

CLMs assume that the effect of the predictor variable ($\beta$) is consistent across outcome categories, which is known as the "proportional odds" assumption. In other words, we assume that what changes across categories are the thresholds ($\theta$) rather than the predictor effects ($\beta$). We can test this assumption using the `nominal_test` function, which compares a model with a single $\beta$ across all outcome categories to a model with a different $\beta$ for each outcome category:

```{r}
nominal_test(mod)
```

If we had gotten a significant $p$ value for any of the rows in the above table, it would mean that a model with varying $\beta$ coefficients for the corresponding variable/interaction provided a better fit, and thus that the proportional odds assumption was violated.

Suppose the proportional odds assumption was violated for the `heels` term. In this case, we could fit a **partial proportional odds** model, where $\beta$ is allowed to vary across categories for `height`, making it a "nominal effect". This is done using the `nominal` argument to `clm`:

```{r}
mod.ppo <- clm(top_shelf ~ heels + height:heels, nominal = ~ height, data = data)
summary(mod.ppo)
```

Notice that now we have 8 threshold coefficients: 4 $\theta$ intercepts and 4 $\beta$ coefficients. If we compare the fit of this model to the previous model, we get one of the rows output by `nominal_test`:

```{r}
anova(mod.ppo, mod)
```

It's important to note that even if the `nominal_test` is significant, this doesn't necessarily mean you *can't* fit a proportional odds model. It's a judgment call:

> "It is well known statistical wisdom that with enough data many goodness of fit tests become sensitive to even minor deviations of little practical relevance" [(Christensen, 2018)](https://cran.uni-muenster.de/web/packages/ordinal/vignettes/clm_article.pdf)

## Plotting CLMs

Visualizing the associations between our predictors and our ordinal outcome variable is straightforward with the `ggeffects` library. This library has a function called `ggpredict` that allows us to predict and then plot the probabilities of each ordinal response level for the different levels of our predictors. To see how it works, we'll first import the necessary libraries:

```{r}
library(ggplot2)
library(ggeffects)
```

### Visualizing continuous predictors

`ggpredict` takes an argument called `terms` that specifies which predictors we're interested in. For continuous predictors, it's a good idea to add `[all]` so that predictions are generated for many values of the continuous predictor and the plot looks smooth:

```{r}
preds_con <- ggpredict(mod, terms = c("height [all]"))
plot(preds_con)
```

It's tempting to interpret these as probability distributions, but they aren't—the areas under the curves don't have to sum to 1. In other words, the probabilities on the y-axes represent the probability of the response level given the predictor level, rather than the probability of the predictor level given the response level. Later, we'll create a custom plot that makes this difference clear.

### Categorical predictors

The syntax for plotting categorical predictors is basically the same, except that it's not necessary to add `[all]` after the name of the predictor:

```{r}
# Generate predicted probabilities
preds_cat <- ggpredict(mod, terms = c("heels"))
plot(preds_cat)
```

For each of these, if we wanted to make sure all of the subplots ("facets" in ggplot terminology) are on the same line, we could add `+ facet_wrap(~response.level, nrow = 1)`:

```{r}
plot(preds_con) + facet_wrap(~response.level, nrow = 1)
plot(preds_cat) + facet_wrap(~response.level, nrow = 1)
```

### Customizing graphs

So far, we've just used a simple call to `plot()`, but this doesn't give us much control over how the plot is rendered (e.g., which variable is represented by which aspect of the plot). For greater control, we can convert the output of `ggpredict` to a `data.frame` object that we then pass to `ggplot`:

```{r}
preds <- ggpredict(mod, terms = c("heels"))
df <- as.data.frame(preds,
                    terms_to_colnames = T) # This is important to include! Otherwise the column names won't correspond to your variable names
head(df)
```

As we can see, we have a different row for each combination of predictor variable level and response variable level, along with the predicted probability of the response given the predictor, and the upper and lower boundaries of the confidence interval (95% by default). We can use this info to create any kind of plot we want:

```{r}
ggplot(df, aes(y = predicted, x = top_shelf, fill = top_shelf)) +
  geom_col(position = position_dodge(), show.legend = F) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = 0) +
  facet_wrap(~heels, nrow = 1,
             labeller = as_labeller(c('No' = 'No heels',
                                      'Yes' = 'Heels'))) +
  scale_fill_gradientn(colours = c('cornflowerblue', 'wheat', 'tomato')) +
  labs(y = 'Response probaility', x = 'Top shelf recruitment frequency') +
  scale_x_discrete(limits = levels(data$top_shelf)) +
  theme_classic() +
  theme(axis.text.x = element_text(size = 6))
```

We can do the same thing for continuous predictors:

```{r}
preds <- ggpredict(mod, terms = c("height [all]"))
df <- as.data.frame(preds,
                    terms_to_colnames = T) # This is important to include!
ggplot(df, aes(x = height, y = predicted, group = top_shelf)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = top_shelf),
              alpha = 0.5) +
  geom_line() +
  scale_fill_gradientn(colours = c('cornflowerblue', 'wheat', 'tomato')) +
  labs(x = 'Height (m)',
       y = 'Response probability',
       fill = sprintf('Top\nshelf\nrecruit.\nfreq.')) +
  theme_classic()
```

This makes it clear what these plots actually represent: each line isn't a probability distribution, but rather, they track the rise and fall in likelihood of each response category across the values of a predictor variable.

## Mixed effects CLMs (CLMMs)

Mixed effects models (AKA mutlilevel/hierarchical/random-effects models) allow us to analyze repeated-measures data without averaging multiple observations together and thereby losing power. In psychology, mixed effects models are often applied when multiple measurements are made from the same participants. Cumulative link mixed effects models (CLMMs) allow us to apply this type of analysis to ordinal data.

Mixed effects models allow us to account for any number of normally distributed "random effects" in our data. In psychology, this usually means accounting for the fact that measurements from the same participant are not independent. The equations underlying CLMMs are the same as those underlying CLMs, except that random effects are incorporated. In our case:

$$ P(Y \leq 1) = \sigma\left( \theta_1 + \beta x + u\right) \\ P(Y \leq 2) = \sigma\left( \theta_2 + \beta x + u\right) \\ \text{etc.} $$

where $u$ is a random variable representing, e.g., a particular participant's random intercept. In contrast, the $\theta$ thresholds and $\beta$ coefficients are fixed effects that are shared across participants. Whereas before we drew an analogy between logistic regression and CLMs, here we can draw an analogy between mixed-effects logistic regression and CLMMs (indeed, when an ordinal variable has only two levels, the CLMMs and mixed-effects logistic regression yield equivalent results; Bousquet, 2021).

Let's suppose we did the same study longitudinally where we followed up with participants as kids and then adults:

```{r}
set.seed(123)
n_obs_per <- 2
n_ptpts <- 100
ptpt_dfs <- list()
for (ptpt_n in seq_len(n_ptpts)) {
  ptpt_intercept <- rnorm(n_obs_per, sd = 0.07)
  cont <- 1.65 + ptpt_intercept + sort(rnorm(n_obs_per, sd = 0.6))
  ptpt_dfs[[ptpt_n]] <- data.frame(
    ptpt = ptpt_n,
    height = cont,
    latent_var = cont + rnorm(n_obs_per, sd = 0.05)
  ) 
} 
data <- do.call(rbind, ptpt_dfs)
data$top_shelf = cut(data$latent_var,
                     breaks = c(-Inf, quantile(data$latent_var,
                                               probs = c(0.1, 0.2, 0.4, 0.8)),
                                Inf),
                     labels = c('Strongly disagree',
                                'Disagree',
                                'Neutral',
                                'Agree',
                                'Strongly agree'))
head(data)
```

Now we have 2 observations per participant. To fit a CLMM to this data, we just need to add the term `(1|ptpt)` to specify that we want a random intercept for each participant. This is the same syntax as the `lmer` function from the `lme4` package:

```{r}
mod.me <- clmm(top_shelf ~ height + (1|ptpt), data = data)
summary(mod.me)
```

## Conclusion

In conclusion, CLMs offer a way to analyze ordinal data that doesn't have a steep learning curve if you are already familiar with multivariate regression. Just as we use ratings to capture some type of assumed continuous psychological construct/variable, CLMs use a latent variable to model ordinal responses. The authors of the `ordinal` package support a pragmatic approach to understand our data, exploring through plots and even fitting a linear model to explore patterns in the data and find a starting point.
