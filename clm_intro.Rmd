# Cumulative link models (CLMs)

TODO:

1.  Figure out any distributional assumptions: if you use logit models, are you assuming a logistically distributed latent variable? Probit models, normally distributed latent variable? There's bound to be a question about this
2.  How do we decide whether to use structured thresholds?
3.  How can one plot CLMMs?
4.  What if one of the predictors is ordinal?

RTC Methods Club, February 20, 2025

Sabrina Valenzano & Isaac Kinley

## Introduction

We're familiar with how to deal with continuous response data (linear regression) and binary data (logistic regression), but what about **ordinal data**?

Ordinal data consists of observations that fall into a series of **ordered levels**. In other words, we know how to arrange the observations in some order, but we don't know anything about the distances between levels. Importantly, even if the levels have numerical labels, it is not appropriate to treat these as observations on a continuous scale.

A common example of ordinal data in psychology is Likert-scale survey responses:

1.  Strongly disagree
2.  Somewhat disagree
3.  Neutral
4.  Somewhat agree
5.  Strongly agree

The wording is chosen so that successive levels seem roughly psychologically equidistant, but we can't pretend we're working with numerical measurements on a continuous scale. In fact, we're working with categorical measurements on an ordinal scale, and cumulative link models (CLMs) are more appropriate for this type of data.

## Terminology

We're using the term "CLM" today because it matches the name of the `clm` function we'll be using, but these models have many other names:

-   Ordinal regression
-   Proportional odds models
-   Ordered logit (or probit)

## CLMs vs logistic regression

To understand CLMs, it's helpful to first review logistic regression. We have some variable $Y$ that can take on values 0 or 1, and we model the probability that it takes on each value according to an intercept $\theta$ a predictor variable or set of variables $x$, and a coefficient or set of coefficients $\beta$ that estimate the relationship between $x$ and $Y$:

$$
P(Y = 1) = \sigma(\theta + x\beta)
$$

Here is how the logistic function $\sigma(x)$ looks (it's sometimes called a "sigmoid" function because it's S-shaped):

```{r}
x <- seq(-5, 5, l = 1000)
plot(plogis(x) ~ x, ylab = 'σ(x)', type = 'l')
```

It's helpful to think of CLMs as a series of logistic regressions. If our observations $Y$ fall into ordinal categories labeled 1, 2, 3, 4, and 5 (as with a Likert-type scale), our model is as follows:

$$
P(Y \leq 1) = \sigma(\theta_1 + x\beta) \\
P(Y \leq 2) = \sigma(\theta_2 + x\beta) \\
P(Y \leq 3) = \sigma(\theta_3 + x\beta) \\
P(Y \leq 4) = \sigma(\theta_4 + x\beta) \\
P(Y \leq 5) = 1 \\
$$

I.e., we are modelling the probability that the observation is less than or equal to 1, less than or equal to 2, etc., with a series of intercepts $\theta_1$, $\theta_2$, etc. and a single set of coefficients $\beta$.

Since we are [...]

## CLM example

Let's generate some imaginary data. Suppose we know people's heights and we've asked whether they agree with the statement "tall people rock" on a Likert scale [Sabrina please let me know if you think of anything better lol]. Don't worry about the details of how we're simulating this—presumably you'll already have your own ordinal data.

```{r}
set.seed(123) # So that we all have the same random data
ndata <- 1000
cont <- 1.65 + rnorm(ndata, sd = 0.07)
categ_effs <- c('A' = 0.5, 'B' = 0.6)
categ <- sample(names(categ_effs), ndata, replace = T)
latent_var <- 0.5*cont + categ_effs[categ] + rnorm(100, sd = 0.1)
data <- data.frame(
  height = cont,
  categ = as.factor(categ),
  agreement = cut(latent_var,
                  breaks = c(-Inf, quantile(latent_var,
                                            probs = c(0.1, 0.2, 0.5, 0.9)),
                             Inf),
                  labels = c('Strongly disagree',
                             'Disagree',
                             'Neutral',
                             'Agree',
                             'Strongly agree'))
)
head(data)
```

We can see from the following boxplot that there is a strong association between height and agreement:

```{r}
boxplot(height ~ agreement, data = data)
```

As much as it might be tempting to run `summary(lm(agreement ~ height, data = data))` and call it a day, this would be pretending our Likert-scale responses are a numerical measurement on a continuous scale, which they aren't. Take a look here when we try to fit a `lm` on ordinal data - we make the false assumption of equal spacing between ordinal categories

```{r}
# # Convert agreement to numeric for plotting
# agreement_numeric <- as.numeric(data$agreement)
# 
# # Fit linear model
# lm_model <- lm(agreement_numeric ~ height, data = data)
# 
# # Plot regression line on raw ordinal data
# plot(height, agreement_numeric, 
#      xlab = "Height", ylab = "Agreement (Numeric)",
#      main = "Linear Model Fit with Ordinal Data",
#      pch = 16, col = "blue")+
# # Add linear regression line
# abline(lm_model, col = "red")

```

As you can see, the figure illustrates that the linear model does not appropriately capture the structure of the ordinal data. The fitted regression line does not align well with the categorical nature of the outcome.

Instead, we'll use the `clm` function from the `ordinal` package :

# Maybe add - and specificy whether the thresholds are equidistant or symmetric to 'indicate to the software that levels of the response variable are equally spaced or symmetrically spaced' (Mangiafico, 2016). These restrictions can be imposed on thresholds if specificity is preferred.

```{r}
library(ordinal)
mod <- clm(agreement ~ height + categ, data = data)
# mod <- clm(agreement ~ height, data = data, threshold = 'equidistant') # I added this threshold specification here since it might be useful to mention the difference between ordinal scales that assume equal distance between ratings and those that are considered 'symmetrically spaced'. I saw above you considered this to be equidistant so I added it here (not that it is necessary but maybe to point out the difference)

anova(mod)
```

This shows us that there is indeed a significant association between height and agreement. As with multivariate linear regression, we can test for associations with multiple variables as well as interactions between these, using the same syntax as we would for the `lm` function.

Notice that there are only 4 "thresholds" or intercepts ($\theta$ in the above equations) even though there are 5 categories. This is because the probability of the observation being less than or equal to the highest category is always 1 (so the corresponding $\theta$ is always implicitly infinity).

```{r}
print(coef(mod))
```

## Plotting CLMs

Visualizing the associations between our predictors and our ordinal outcome variable is straightforward with the `ggeffects` library. This library has a function called `ggpredict` that allows us to predict and then plot the probabilities of each ordinal response level for the different levels of our predictors. To see how it works, we'll first import the necessary libraries:

```{r}
library(ggplot2)
library(ggeffects)
```

### Visualizing continuous predictors

`ggpredict` takes an argument called `terms` that specifies which predictors we're interested in. For continuous predictors, it's a good idea to add `[all]` so that predictions are generated for many values of the continuous predictor and the plot looks smooth:

```{r}
preds_con <- ggpredict(mod, terms = c("height [all]"))
plot(preds_con)
```

It's tempting to interpret these as probability distributions, but they aren't—the areas under the curves don't have to sum to 1. In other words, the probabilities on the y-axes represent the probability of the response level given the predictor level, rather than the probability of the predictor level given the response level.

### Categorical predictors

The syntax for plotting categorical predictors is basically the same, except that it's not necessary to add `[all]` after the name of the predictor:

```{r}
# Generate predicted probabilities
preds_cat <- ggpredict(mod, terms = c("categ"))
plot(preds_cat)
```

For each of these, if we wanted to make sure all of the subplots ("facets" in ggplot terminology) are on the same line, we could add `+ facet_wrap(~response.level, nrow = 1)`:

```{r}
plot(preds_con) + facet_wrap(~response.level, nrow = 1)
plot(preds_cat) + facet_wrap(~response.level, nrow = 1)
```

### Customizing graphs

So far, we've just used a simple call to `plot()`, but this doesn't give us much control over how the plot is rendered (e.g., which variable is represented by which aspect of the plot). For greater control, we can convert the output of `ggpredict` to a `data.frame` object that we then pass to `ggplot`:

```{r}
preds <- ggpredict(mod, terms = c("categ"))
df <- as.data.frame(preds,
                    terms_to_colnames = T) # This is important to include! Otherwise the column names won't correspond to your variable names
head(df)
```

As we can see, we have a different row for each combination of predictor variable level and response variable level, along with the predicted probability of the response given the predictor, and the upper and lower boundaries of the confidence interval (95% by default). We can use this info to create any kind of plot we want:

```{r}
ggplot(df, aes(y = predicted, x = agreement, fill = agreement)) +
  geom_col(position = position_dodge()) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = 0) +
  facet_wrap(~categ, nrow = 1) +
  scale_fill_gradientn(colours = c('cornflowerblue', 'wheat', 'tomato')) +
  theme_classic()
```

We can do the same thing for continuous predictors:

```{r}
preds <- ggpredict(mod, terms = c("height [all]"))
df <- as.data.frame(preds,
                    terms_to_colnames = T) # This is important to include!
ggplot(df, aes(x = height, y = predicted, group = agreement)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = agreement),
              alpha = 0.5) +
  geom_line() +
  scale_fill_gradientn(colours = c('cornflowerblue', 'wheat', 'tomato')) +
  theme_classic()
```

## Mixed effects CLMs (CLMMs)

Cumulative link mixed effects models (CLMMs) allow us to run ordinal regression while accounting for any amount of normally distributed random effects, making them suitable for data that includes repeated measurements from the same participants.

You will notice that the syntax for clmms is similar to the formula used for lmer from the lme4 package.

Note: when the ordinal variable has only two levels, both the CLMM approach and random-effect logistic regression yield equivalent results (Bousquet, 2021).
